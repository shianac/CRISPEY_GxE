#!/usr/bin/env nextflow

params.conda_env = "/opt/modules/pkgs/anaconda/4.8/envs/CRISPEY_GxE"
 
params.working_folder = "$HOME/GXE_publication/test_read_processing/"

params.admera_sample_index = "18146-52"

params.data_folder = "$HOME/GXE_publication/test_data/"

FASTQ_INPUT_0 = Channel.fromFilePairs(params.data_folder + "fastq/*_{[A-Z,a-z,0-9]*_[A-Z,a-z,0-9]*_R1,[A-Z,a-z,0-9]*_[A-Z,a-z,0-9]*_R2}_001.fastq.gz")

params.sample_key_file = "$HOME/GXE_publication/test_data/test-Sample Key.tsv"
    
MERGED_CHANNEL = Channel
    .fromPath(params.sample_key_file)
    .splitCsv(sep:'\t',skip: 1 ).join(FASTQ_INPUT_0)
/*
 * Step 1. Concatenate fastq files from multiple runs
 */

process merge_lanes{

    input:
    tuple fastq_index, sample_name, fastq_0 from MERGED_CHANNEL

    output:
    set fastq_index, sample_name, file('R1_fastq.gz'), file('R2_fastq.gz') into FASTQ_CAT

    script:
    """
    cat ${fastq_0[0]} > R1_fastq.gz
    cat ${fastq_0[1]} > R2_fastq.gz
    """
}

/*
 * Step 2. Trim pair-end reads with Cutadapt
 */

params.CUTADAPT_BIN = "/opt/modules/pkgs/anaconda/4.8/envs/CRISPEY2/bin/cutadapt"
params.adapter_5prime = 'GGCCAGTTTAAACTT'
params.adapter_3prime = 'GCATGGC'
params.num_of_cores = "12"
params.err = "0.2"
params.barcode_len = "27"
params.output_dir_name = 'trimmed'


process trim{
    input:
    set fastq_index, sample_name, file('R1_fastq.gz'), file('R2_fastq.gz') from FASTQ_CAT
    
    output:
    set fastq_index, sample_name, file('R2.trimmed.fastq.gz'), file('R1.trimmed.fastq.gz') into TRIMMED_FILES
    
    script:
    """
    $params.CUTADAPT_BIN -g $params.adapter_5prime...$params.adapter_3prime -j $params.num_of_cores -e $params.err -q 20 --discard-untrimmed -m $params.barcode_len --pair-filter=first -o R2.trimmed.fastq.gz -p R1.trimmed.fastq.gz R2_fastq.gz R1_fastq.gz
    """
}

/*
 * Step 3. Align trimmed reads using FLASh
 */
 
input:
params.FLASH_BIN = "/opt/modules/pkgs/anaconda/4.8/envs/CRISPEY_GxE/bin/flash"
params.min_overlap = 12
params.max_mismatch = 0.25

process align {
    input:
    set fastq_index, sample_name, file('R2.trimmed.fastq.gz'), file('R1.trimmed.fastq.gz') from TRIMMED_FILES
    
    output:
    set fastq_index, sample_name, file('out.extendedFrags.fastq.gz'), file('out.notCombined_1.fastq.gz'), file('out.notCombined_2.fastq.gz'), file('out.hist'), file('out.histogram') into MATCHED_READS
    
    script:
    """
    $params.FLASH_BIN -m $params.min_overlap -x $params.max_mismatch --compress R2.trimmed.fastq.gz R1.trimmed.fastq.gz
    """
}

/*
 * Step 4. Filter and count reads with custom python script and write counts file
 */

process count {
    conda params.conda_env
    
    input: 
    set fastq_index, sample_name, file('out.extendedFrags.fastq.gz'), file('out.notCombined_1.fastq.gz'), file('out.notCombined_2.fastq.gz'), file('out.hist'), file('out.histogram') from MATCHED_READS
    
    output:
    set fastq_index, sample_name, file('counts.csv') into BARCODE_COUNTS
    
    script:
    """
    #!/usr/bin/env python3
    # Roy Ang counting functions
    import os
    import gzip
    from Bio import SeqIO
    from Bio import pairwise2
    import pandas as pd
    
    fastq_merged = 'out.extendedFrags.fastq.gz'
    
    def count_barcodes(fastq_file):
        '''
        takes a fastq file and counts all valid barcodes (27bp long)
        '''
        barcode_dict = {}
        with gzip.open(fastq_file, 'rt') as fastq:
            for read in SeqIO.parse(fastq, "fastq"):
                if len(read.seq) == 27:
                    if str(read.seq) not in barcode_dict:
                        barcode_dict[str(read.seq)] = 1
                    else:
                        barcode_dict[str(read.seq)] += 1
        return barcode_dict
    
    #write file:
    barcode_dict = count_barcodes(fastq_merged)
    count_df = pd.DataFrame(list(barcode_dict.items()), columns=['barcode', 'counts'])
    count_df.to_csv('counts.csv', sep='\t') 
    
    """
}


/*
 * Step 5. save counts file into output directory
 */

process save_counts{
    publishDir params.working_folder+ 'counts_withUMI/', mode: 'copy', overwrite: false
    
    input:
    set fastq_index, sample_name, counts_file from BARCODE_COUNTS
    
    output:
    file '*'
    
    script:
    """
    cat $counts_file > ${sample_name}_counts.tsv
    """
}

println "done"
